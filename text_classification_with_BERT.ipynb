{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to use **BERT** to perform **text classification**.\n",
    "\n",
    "We'll be using the [Stanford Sentiment Treebank](https://nlp.stanford.edu/sentiment/index.html) (SST-2) dataset of movie reviews and a smaller version of BERT - [DistilBERT](https://huggingface.co/transformers/model_doc/distilbert.html) - developed by HuggingFace. Our goal is to classify our moview reviews as positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by loading and checking the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Perform initial imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from torchtext import data, datasets\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential=False since we don't want to tokenize the text\n",
    "# lowercased text\n",
    "text_data = data.Field(sequential=False, lower=True)\n",
    "\n",
    "label_data = data.Field(sequential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = datasets.SST.splits(text_data, label_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': <torchtext.data.field.Field at 0x2c6849ceca0>,\n",
       " 'label': <torchtext.data.field.Field at 0x2c6849cee50>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check train fields\n",
    "\n",
    "train.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the rock is destined to be the 21st century 's new `` conan '' and that he 's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check first review\n",
    "\n",
    "train[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check first label\n",
    "\n",
    "train[0].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8544"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to count the number of reviews with any given label\n",
    "\n",
    "def label_count(sst_data):\n",
    "    \n",
    "    labels = []\n",
    "\n",
    "    for i in range(len(sst_data)):\n",
    "        labels.append(sst_data[i].label)\n",
    "        \n",
    "    counts = Counter(labels)\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'positive': 3610, 'neutral': 1624, 'negative': 3310})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_count(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 8544 moview reviews in total. From these, **3610** are classified as **positive**, 1624 as neutral and **3310** as **negative**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we intend to use the **SST-2 dataset (binary classification)**, we are only interested in the reviews classified as positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = datasets.SST.splits(text_data, label_data, \n",
    "                                       filter_pred=lambda x: x.label != 'neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'positive': 3610, 'negative': 3310})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_count(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have **6920 moview reviews: 3610 are labeled as positive and 3310 are labeled as negative**. Our data is now correctly loaded and we can proceed with our project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Create a dataframe and select a subset of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "\n",
    "for i in range(len(train)):\n",
    "    data = {}\n",
    "    data['review']=train[i].text\n",
    "    data['label']=train[i].label\n",
    "    train_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': \"the rock is destined to be the 21st century 's new `` conan '' and that he 's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\",\n",
       " 'label': 'positive'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the rock is destined to be the 21st century 's...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the gorgeously elaborate continuation of `` th...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>singer\\/composer bryan adams contributes a sle...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yet the act is still charming here .</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>whether or not you 're enlightened by any of d...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review     label\n",
       "0  the rock is destined to be the 21st century 's...  positive\n",
       "1  the gorgeously elaborate continuation of `` th...  positive\n",
       "2  singer\\/composer bryan adams contributes a sle...  positive\n",
       "3               yet the act is still charming here .  positive\n",
       "4  whether or not you 're enlightened by any of d...  positive"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6920"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    3610\n",
       "negative    3310\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of both labels\n",
    "\n",
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also save our dataframe as a `.tsv` file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder if it does not exist\n",
    "\n",
    "output_dir = './.data/sst/tsv'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df_train as a .tsv file\n",
    "\n",
    "df_train.to_csv('./.data/sst/tsv/train.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For performance reasons, we'll be using only **half of the training dataset** for our text classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train.sample(frac=0.5, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e.t. works because its flabbergasting principa...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>from the dull , surreal ache of mortal awarene...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a disoriented but occasionally disarming saga ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the only type of lives this glossy comedy-dram...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in the affable maid in manhattan , jennifer lo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a must for fans of british cinema , if only be...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>earnest and heartfelt but undernourished and p...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>` anyone with a passion for cinema , and indee...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>we never feel anything for these characters , ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>- style cross-country adventure ... it has spo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review     label\n",
       "0  e.t. works because its flabbergasting principa...  positive\n",
       "1  from the dull , surreal ache of mortal awarene...  positive\n",
       "2  a disoriented but occasionally disarming saga ...  positive\n",
       "3  the only type of lives this glossy comedy-dram...  negative\n",
       "4  in the affable maid in manhattan , jennifer lo...  positive\n",
       "5  a must for fans of british cinema , if only be...  positive\n",
       "6  earnest and heartfelt but undernourished and p...  positive\n",
       "7  ` anyone with a passion for cinema , and indee...  positive\n",
       "8  we never feel anything for these characters , ...  negative\n",
       "9  - style cross-country adventure ... it has spo...  positive"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3460"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    1849\n",
       "negative    1611\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 3460 reviews, from which 1849 are positive and 1611 are negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of longest review\n",
    "\n",
    "max([len(review.split()) for review in df['review']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average length of the reviews\n",
    "\n",
    "np.rint(np.mean([len(review.split()) for review in df['review']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our reviews have an **average length of 19 words** and the **longest review has 52 words**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use **DistilBERT to tokenize our reviews**. This will be our **step 2**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Perform necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers as pytt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using DistilBERT\n",
    "model_class, tokenizer_class, pretrained_weights = (pytt.DistilBertModel, pytt.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "# load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the **DistilBERT model**, more specifically the [distilbert-base-uncased model](https://huggingface.co/transformers/pretrained_models.html), trained on lower-cased English text since our reviews are also lower-cased.\n",
    "\n",
    "We are now ready to tokenize our reviews. Besides tokenization, we'll also perform padding so that our reviews have all the same length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Tokenize and padd reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_length=70 should be enough for all tokens, including special tokens\n",
    "\n",
    "df_tokenized_padded = df['review'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, \n",
    "                                                              max_length=70, \n",
    "                                                              pad_to_max_length=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [101, 1041, 1012, 1056, 1012, 2573, 2138, 2049...\n",
       "1    [101, 2013, 1996, 10634, 1010, 16524, 12336, 1...\n",
       "2    [101, 1037, 4487, 21748, 25099, 2094, 2021, 56...\n",
       "3    [101, 1996, 2069, 2828, 1997, 3268, 2023, 1950...\n",
       "4    [101, 1999, 1996, 21358, 7011, 3468, 10850, 19...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokenized_padded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 1041,\n",
       " 1012,\n",
       " 1056,\n",
       " 1012,\n",
       " 2573,\n",
       " 2138,\n",
       " 2049,\n",
       " 13109,\n",
       " 7875,\n",
       " 4059,\n",
       " 14083,\n",
       " 2075,\n",
       " 27928,\n",
       " 1010,\n",
       " 2403,\n",
       " 1011,\n",
       " 2095,\n",
       " 1011,\n",
       " 2214,\n",
       " 2728,\n",
       " 6097,\n",
       " 2532,\n",
       " 18533,\n",
       " 2239,\n",
       " 1010,\n",
       " 1020,\n",
       " 1011,\n",
       " 2095,\n",
       " 1011,\n",
       " 2214,\n",
       " 3881,\n",
       " 6287,\n",
       " 5974,\n",
       " 1998,\n",
       " 2184,\n",
       " 1011,\n",
       " 2095,\n",
       " 1011,\n",
       " 2214,\n",
       " 2888,\n",
       " 2726,\n",
       " 1010,\n",
       " 8054,\n",
       " 2149,\n",
       " 1997,\n",
       " 1996,\n",
       " 4598,\n",
       " 1997,\n",
       " 1996,\n",
       " 7968,\n",
       " 1010,\n",
       " 15536,\n",
       " 10431,\n",
       " 2098,\n",
       " 10367,\n",
       " 2013,\n",
       " 1037,\n",
       " 2521,\n",
       " 9497,\n",
       " 4774,\n",
       " 1012,\n",
       " 102,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokenized_padded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_tokenized_padded[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our reviews are now tokenized and include special tokens like the **\\[CLS\\]** token - id 101 - at the beginning of each review and the **\\[SEP\\]** token - id 102 - at the end. Note that each token was replaced by its corresponding id from the embedding table of the pretrained model we loaded.\n",
    "\n",
    "The reviews have also been padded with 0's so that they all have the same length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Get reviews in the correct shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3460,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokenized_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_tokenized_padded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our reviews are stored as a one dimensional tensor (a vector) with 3460 rows, but we need a two dimensional tensor (a matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_reviews = np.array([review for review in df_tokenized_padded.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,  1041,  1012, ...,     0,     0,     0],\n",
       "       [  101,  2013,  1996, ...,     0,     0,     0],\n",
       "       [  101,  1037,  4487, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,  2035,  1996, ...,     0,     0,     0],\n",
       "       [  101,  1037, 20161, ...,     0,     0,     0],\n",
       "       [  101,  1996,  4164, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3460, 70)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to create a mask in order for our model to be able distinguish the padding from the rest of the tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Create attention mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_attention_mask = np.where(arr_reviews != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3460, 70)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_attention_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have everything we need to **feed the reviews to our DistilBERT model** - this is our **step 3**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(arr_reviews, dtype=torch.int64) # a long tensor is expected\n",
    "attention_mask = torch.tensor(arr_attention_mask, dtype=torch.int64) # a long tensor is expected\n",
    "# PyTorch data types: https://pytorch.org/docs/stable/tensor_attributes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Feed reviews to DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# disabling gradient calculation\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(last_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(last_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3460, 70, 768])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our output is a one dimensional tuple. It stores a torch tensor of shape **(number of reviews, length of padded reviews, number of hidden units of our DistilBERT model)**.\n",
    "\n",
    "We are interested in the **output for the \\[CLS\\] token only** since we are dealing with a classification task. Let's slice our output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Slice output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to keep the output for all our reviews, but only what corresponds to the first token (the \\[CLS\\] token) of each one. We also want to keep the output of all the hidden units, i. e., the slice `[:, 0, :]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_BERT = last_hidden_states[0][:, 0, :].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3460, 768)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_BERT.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a 2D numpy array with the desired embeddings for each review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train our classifier, we only need to check our labels and we are good to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Check labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3460,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels for our 3460 reviews are stored in the variable `labels`. We can proceed to our **step 4 and train our classifier**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Perform necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Split train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reviews_BERT, labels, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2422, 768)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1038, 768)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use 2422 reviews to train our classifier and 1038 to test it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create model and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_clf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "review_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = review_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'negative', 'positive', 'positive', 'negative',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our classifier seems to be working correctly. It's now time to evaluate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot confusion matrix\n",
    "\n",
    "plot_confusion_matrix(review_clf, X_test, y_test, \n",
    "                      labels=sorted(review_clf.classes_, reverse=True), # to have positive first\n",
    "                      values_format='.3g',\n",
    "                      cmap=plt.cm.Blues);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our plot confirms our previous idea. The **true positives (left upper corner)** and **true negatives (right lower corner)** clearly dominate our predictions.\n",
    "\n",
    "With these values we can calculate both the **precision and recall** of our classifier. These two metrics can then be combined to calculate the **f1-score**, which represents an equal tradeoff between precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.88      0.84       453\n",
      "    positive       0.90      0.83      0.86       585\n",
      "\n",
      "    accuracy                           0.85      1038\n",
      "   macro avg       0.85      0.85      0.85      1038\n",
      "weighted avg       0.86      0.85      0.85      1038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# precision, recall and f1-score\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our precision and recall are quite similar, and so is our f1-score. Since our dataset is almost evenly balanced, a metric like **accuracy** can also be used to properly evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.850674373795761\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a final **accuracy of 85,1%**, which is a very interesting result considering the overall simplicity of our approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, in the paper [DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/pdf/1910.01108v4.pdf), DistilBERT achieves an **accuray score of 91.3%** and the highest score to date (May 7, 2020) for this dataset is achieved by T5-3B: **97,4% accuracy**!! You can check [this page](https://paperswithcode.com/sota/sentiment-analysis-on-sst-2-binary) for the current state-of-the-art results with the SST-2 dataset.\n",
    "\n",
    "This project was based on Jay Alammar's blog post, [A Visual Guide to Using BERT for the First Time](https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/). Please check it out if you want to know more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
